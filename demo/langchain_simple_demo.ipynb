{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f074218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain langchain_community langchain-openai langgraph bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78baeef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from IPython.display import HTML, display\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "from lettucedetect_api.client import LettuceClient\n",
    "from lettucedetect_api.models import TokenDetectionItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d803f6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_output(predictions: list[TokenDetectionItem]) -> None:\n",
    "    text = [item.token for item in predictions]\n",
    "    colors = [f\"rgba(255, 0, 0, {item.hallucination_score * 0.8})\" for item in predictions]\n",
    "    html_elements = [\n",
    "        f'<span style=\"background-color: {color};\">{text}</span>'\n",
    "        for color, text in zip(colors, text)\n",
    "    ]\n",
    "    html = \"\".join(html_elements)\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4784649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Components\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "lettuce_client = LettuceClient(\"http://127.0.0.1:8000\")\n",
    "\n",
    "system_message = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"If you don't know the answer, just say that you don't know. \"\n",
    "    \"Always add facts about sea life and related those facts to the context in a funny and creative way. \"\n",
    "    \"Don't use emojis.\"\n",
    ")\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_message),\n",
    "        (\"user\", \"Context: {context}\\nQuestion: {question}\\n\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b680f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load, chunk and index contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(class_=(\"post-content\", \"post-title\", \"post-header\"))\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1559a954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    context: List[Document]\n",
    "    question: str\n",
    "    answer: str\n",
    "    hallucination_scores: list\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt_template.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    hallucination_scores = lettuce_client.detect_token(\n",
    "        contexts=[docs_content],\n",
    "        question=state[\"question\"],\n",
    "        answer=response.content,\n",
    "    )\n",
    "    return {\n",
    "        \"answer\": response.content,\n",
    "        \"hallucination_scores\": hallucination_scores.predictions,\n",
    "    }\n",
    "\n",
    "\n",
    "# Compile application\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28dfc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "display_output(response[\"hallucination_scores\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lettuce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
